{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_pytorch import ViT\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_data = datasets.FashionMNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.FashionMNIST(root='data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_transform(data):\n",
    "    processed_data = []\n",
    "    for img, _ in data:\n",
    "        img_np = img.numpy().squeeze()\n",
    "        fft = np.fft.fft2(img_np)\n",
    "        processed_data.append((fft.real, fft.imag))\n",
    "    return processed_data\n",
    "\n",
    "train_fft = fft_transform(train_data)\n",
    "test_fft = fft_transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7334c5cdbfa0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.abs(train_fft[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransform:\n",
    "    def __call__(self, sample):\n",
    "        real, imag = sample      \n",
    "        # Stack the image and FFT side by side\n",
    "        combined = np.concatenate([real, imag], axis=1)\n",
    "        return torch.from_numpy(combined).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = CustomTransform()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        sample = self.transform(sample)\n",
    "        return sample[None,:,:], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938\n"
     ]
    }
   ],
   "source": [
    "# Create the custom dataset\n",
    "train_labels = [label for _, label in train_data]\n",
    "train_dataset = ComplexDataset(train_fft, train_labels) \n",
    "\n",
    "test_labels = [label for _, label in test_data]\n",
    "test_dataset = ComplexDataset(test_fft, test_labels)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT(\n",
    "    image_size = 56,\n",
    "    patch_size = 7,\n",
    "    num_classes = 10,\n",
    "    dim = 256,\n",
    "    depth = 6,\n",
    "    heads = 12,\n",
    "    mlp_dim = 512,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1,\n",
    "    channels = 1\n",
    ")\n",
    "\n",
    "img = torch.randn(1, 1, 28, 56)\n",
    "\n",
    "preds = model(img) # (1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 6337132\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/experiment_1') \n",
    "\n",
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}\", unit=\"batch\")\n",
    "    for batch_idx, (data, target) in enumerate(progress_bar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "        progress_bar.set_postfix({\"Train Loss\": train_loss / (batch_idx + 1), \"Train Acc\": 100. * correct / total})\n",
    "        \n",
    "        # Log batch-level metrics\n",
    "        writer.add_scalar('Loss/Train Batch', loss.item(), epoch * len(train_loader) + batch_idx)\n",
    "        writer.add_scalar('Accuracy/Train Batch', 100. * correct / total, epoch * len(train_loader) + batch_idx)\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = 100. * correct / total\n",
    "    \n",
    "    # Log epoch-level metrics\n",
    "    writer.add_scalar('Loss/Train Epoch', train_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Train Epoch', train_accuracy, epoch)\n",
    "    \n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "def test(model, device, test_loader, criterion, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = 100. * correct / total\n",
    "    \n",
    "    # Log epoch-level metrics\n",
    "    writer.add_scalar('Loss/Test', test_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/Test', test_accuracy, epoch)\n",
    "    \n",
    "    return test_loss, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 938/938 [01:15<00:00, 12.45batch/s, Train Loss=0.517, Train Acc=81.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 0.5166, Train Accuracy: 81.59%\n",
      "Test Loss: 0.3587, Test Accuracy: 86.95%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 938/938 [01:15<00:00, 12.40batch/s, Train Loss=0.33, Train Acc=88]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "Train Loss: 0.3304, Train Accuracy: 87.96%\n",
      "Test Loss: 0.3338, Test Accuracy: 88.03%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 938/938 [01:15<00:00, 12.39batch/s, Train Loss=0.287, Train Acc=89.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "Train Loss: 0.2867, Train Accuracy: 89.48%\n",
      "Test Loss: 0.3272, Test Accuracy: 88.51%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 938/938 [01:16<00:00, 12.34batch/s, Train Loss=0.257, Train Acc=90.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "Train Loss: 0.2566, Train Accuracy: 90.47%\n",
      "Test Loss: 0.3037, Test Accuracy: 89.01%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 938/938 [01:15<00:00, 12.39batch/s, Train Loss=0.227, Train Acc=91.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "Train Loss: 0.2267, Train Accuracy: 91.59%\n",
      "Test Loss: 0.3142, Test Accuracy: 89.13%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 938/938 [01:15<00:00, 12.41batch/s, Train Loss=0.202, Train Acc=92.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "Train Loss: 0.2019, Train Accuracy: 92.57%\n",
      "Test Loss: 0.3200, Test Accuracy: 89.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7:  80%|████████  | 752/938 [01:00<00:15, 12.40batch/s, Train Loss=0.178, Train Acc=93.4]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m test(model, device, test_loader, criterion, epoch)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 16\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.to(device)\n",
    "epochs = 500\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_accuracy = train(model, device, train_loader, optimizer, criterion, epoch)\n",
    "    test_loss, test_accuracy = test(model, device, test_loader, criterion, epoch)\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    print()\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
